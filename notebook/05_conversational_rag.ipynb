{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fbdc08",
   "metadata": {},
   "source": [
    "# üìñ Chapter 05 ‚Äî Conversation Memory & Source Citations\n",
    "## üéØ Objectives\n",
    "Enhance RAG system with conversation memory and source citations.\n",
    "**What we'll accomplish:**\n",
    "- Add conversation memory for multi-turn dialogues\n",
    "- Implement source citations for transparency\n",
    "- Test and compare improvements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d54272",
   "metadata": {},
   "source": [
    "## üí¨ Part 1 ‚Äî Conversation Memory\n",
    "### üí¨ Step 01 ‚Äî Setup & Load RAG Chain\n",
    "\n",
    "Import libraries and load the basic RAG chain from Chapter 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d38c513b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from src.rag.embeddings import create_embedding_model\n",
    "from src.rag.vector_store import create_vector_store\n",
    "from src.rag.llm import create_llm\n",
    "from src.rag.prompts import get_default_rag_prompt\n",
    "from src.rag.rag_chain import create_rag_chain\n",
    "from src.utils.emoji_log import done, info, success, task, data\n",
    "\n",
    "info(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb72a67",
   "metadata": {},
   "source": [
    "### üì¶ Step 02 ‚Äî Load Basic RAG Components\n",
    "\n",
    "Load the vector store, LLM, and create a basic RAG chain (without memory first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9e793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading RAG components...\n",
      "üí¨ Loading embedding model...\n",
      "üèÅ Embedding model loaded\n",
      "üí¨ Loading vector store...\n",
      "üèÅ Vector store loaded\n",
      "üí¨ Creating LLM...\n",
      "üèÅ LLM created\n",
      "üí¨ Creating basic RAG chain...\n",
      "üèÅ Basic RAG chain created\n",
      "‚úÖ All components loaded!\n"
     ]
    }
   ],
   "source": [
    "task(\"Loading RAG components...\")\n",
    "\n",
    "# 1. Load embedding model\n",
    "info(\"Loading embedding model...\")\n",
    "embeddings = create_embedding_model()\n",
    "done(\"Embedding model loaded\")\n",
    "\n",
    "# 2. Load vector store\n",
    "info(\"Loading vector store...\")\n",
    "vector_store = create_vector_store(\n",
    "    collection_name=\"travel_attractions\", embeddings=embeddings\n",
    ")\n",
    "done(\"Vector store loaded\")\n",
    "\n",
    "# 3. Create LLM\n",
    "info(\"Creating LLM...\")\n",
    "llm = create_llm()\n",
    "done(\"LLM created\")\n",
    "\n",
    "# 4. Get prompt template\n",
    "prompt = get_default_rag_prompt()\n",
    "\n",
    "# 5. Create basic RAG chain (without memory)\n",
    "info(\"Creating basic RAG chain...\")\n",
    "basic_rag_chain = create_rag_chain(\n",
    "    llm=llm, vector_store=vector_store, prompt=prompt, k=5\n",
    ")\n",
    "done(\"Basic RAG chain created\")\n",
    "success(\"All components loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac14b2e",
   "metadata": {},
   "source": [
    "### üß™ Step 03 ‚Äî Test Basic RAG (Without Memory)\n",
    "\n",
    "Test the basic RAG chain with a multi-turn conversation to see what happens without memory.\n",
    "\n",
    "**Expected behavior:** The chain will NOT remember previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e629eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Testing basic RAG without conversation memory...\n",
      "======================================================================\n",
      "Question 1: What is the Space Needle?\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 9.539848153s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2958\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   2957\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2958\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2959\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2960\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2961\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\google\\genai\\models.py:5218\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5217\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5218\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5222\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\google\\genai\\models.py:4000\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3998\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4000\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4005\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4006\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\google\\genai\\_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1385\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m response_body = (\n\u001b[32m   1390\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\google\\genai\\_api_client.py:1201\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1194\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1195\u001b[39m     method=http_request.method,\n\u001b[32m   1196\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1199\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1200\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 9.539848153s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuestion 1: What is the Space Needle?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m answer1 = \u001b[43mbasic_rag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the Space Needle?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Question 2: Follow-up question using \"it\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3143\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3141\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3142\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3143\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3145\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2461\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2458\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2459\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2962\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   2958\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   2959\u001b[39m         **request,\n\u001b[32m   2960\u001b[39m     )\n\u001b[32m   2961\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2962\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\travel-rag-k8jaxz6c-py3.13\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 9.539848153s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}"
     ]
    }
   ],
   "source": [
    "task(\"Testing basic RAG without conversation memory...\")\n",
    "\n",
    "# Question 1: Ask about Space Needle\n",
    "print(\"=\" * 70)\n",
    "print(\"Question 1: What is the Space Needle?\")\n",
    "print(\"=\" * 70)\n",
    "answer1 = basic_rag_chain.invoke(\"What is the Space Needle?\")\n",
    "print(f\"Answer: {answer1}\")\n",
    "\n",
    "# Question 2: Follow-up question using \"it\"\n",
    "print(\"=\" * 70)\n",
    "print(\"Question 2: How tall is it?\")\n",
    "print(\"=\" * 70)\n",
    "print(\"(Without memory, the chain doesn't know what 'it' refers to)\")\n",
    "answer2 = basic_rag_chain.invoke(\"How tall is it?\")\n",
    "print(f\"Answer: {answer2}\")\n",
    "\n",
    "# Question 3: Another follow-up\n",
    "print(\"=\" * 70)\n",
    "print(\"Question 3: What else is nearby?\")\n",
    "print(\"=\" * 70)\n",
    "print(\"(Without memory, the chain doesn't know we were talking about Space Needle)\")\n",
    "answer3 = basic_rag_chain.invoke(\"What else is nearby?\")\n",
    "print(f\"Answer: {answer3}\")\n",
    "info(\n",
    "    \"Notice: Without memory, the chain cannot understand context from previous questions!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7fa42",
   "metadata": {},
   "source": [
    "### üß† Step 04 ‚Äî Add Conversation Memory\n",
    "\n",
    "Now let's add conversation memory to enable multi-turn dialogues.\n",
    "\n",
    "**Key Components:**\n",
    "- `ChatMessageHistory`: Store chat messages\n",
    "- `RunnableWithMessageHistory`: Integrate memory with chain\n",
    "- Session management for conversation tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f06f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a store for chat histories\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "\n",
    "    return store[\n",
    "        session_id\n",
    "    ]  # This is a ChatMessageHistory instance which has attribute called message\n",
    "\n",
    "    # e.g\n",
    "    # store[\"user_1\"].messages = [\n",
    "    #   HumanMessage(content=\"What is the Space Needle?\"),\n",
    "    #   AIMessage(content=\"The Space Needle is...\")\n",
    "    # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b538abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a new prompt template that includes chat history\n",
    "conversational_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # This is a tuple, tell AI the system message\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a helpful travel assistant specializing in tourist attractions.\n",
    "Use the following context to answer the question. The context contains information about various tourist attractions.\n",
    "Context:\n",
    "{context}\n",
    "Instructions:\n",
    "- Answer based ONLY on the information provided in the context above\n",
    "- If the context doesn't contain relevant information, say \"I don't have information about that in my database\"\n",
    "- Be concise and helpful\n",
    "- Use the conversation history to understand context and pronouns\"\"\",\n",
    "        ),\n",
    "        # This is a placeholder here to insert the chat history\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        # Another tuple, user message\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a44e3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548bae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build conversational RAG chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "conversational_rag_chain = (\n",
    "    RunnablePassthrough().assign(\n",
    "        context=lambda x: format_docs(retriever.invoke(x[\"question\"]))\n",
    "    )  # question & chat_history were assigned automatically\n",
    "    | conversational_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0ec257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Wrap with message history\n",
    "conversational_chain_with_history = RunnableWithMessageHistory(\n",
    "    conversational_rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task(\"Testing conversational RAG with memory...\")\n",
    "\n",
    "session_id = \"user_123\"\n",
    "\n",
    "# Question 1: Ask about Space Needle\n",
    "print(\"=\" * 70)\n",
    "print(\"Question 1: What is the Space Needle?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "answer1 = conversational_chain_with_history.invoke(\n",
    "    input={\"question\": \"What is the Space Needle?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "print(f\"Answer: {answer1}\")\n",
    "\n",
    "# Question 2: Follow-up question using \"it\"\n",
    "print(\"=\" * 70)\n",
    "print(\"Question 2: How tall is it?\")\n",
    "print(\"=\" * 70)\n",
    "answer2 = conversational_chain_with_history.invoke(\n",
    "    {\"question\": \"How tall is it?\"}, config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(f\"Answer: {answer2}\")\n",
    "\n",
    "# Question 3: Another follow-up\n",
    "print(\"=\" * 70)\n",
    "print(\"Question 3: What else is nearby?\")\n",
    "print(\"=\" * 70)\n",
    "print(\"(With memory, the chain should remember we're talking about Space Needle)\")\n",
    "answer3 = conversational_chain_with_history.invoke(\n",
    "    {\"question\": \"What else is nearby?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "print(f\"Answer: {answer3}\")\n",
    "\n",
    "success(\"Conversation memory is working! The chain remembers context from previous questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the stored history\n",
    "history = get_session_history(session_id)\n",
    "for msg in history.messages:\n",
    "    print(f\"{msg.__class__.__name__}: {msg.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47447dff",
   "metadata": {},
   "source": [
    "## üìö Part 2 ‚Äî Source Citations\n",
    "### üìÑ Step 05 ‚Äî Return Source Documents\n",
    "\n",
    "Modify RAG chain to return source documents alongside answers.\n",
    "\n",
    "**Why do we need this?**\n",
    "- Transparency: Users can see where the answer comes from\n",
    "- Verification: Users can check the original sources\n",
    "- Trust: Increases confidence in the system's responses\n",
    "\n",
    "**What we'll do:**\n",
    "1. Create a function to retrieve and prepare data\n",
    "2. Use `RunnableParallel` to return both answer and sources\n",
    "3. Wrap with message history\n",
    "4. Test the enhanced chain\n",
    "\n",
    "**Key concept:** `RunnableParallel` allows us to execute multiple operations simultaneously and combine their results into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1bb0716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Building RAG chain with source documents...\n",
      "üèÅ Retrieve and prepare function created\n"
     ]
    }
   ],
   "source": [
    "info(\"Building RAG chain with source documents...\")\n",
    "\n",
    "\n",
    "# Create a function to retrieve documents and prepare data\n",
    "def retrieve_and_prepare(x):\n",
    "    docs = retriever.invoke(input=x[\"question\"])\n",
    "    return {\n",
    "        \"question\": x[\"question\"],\n",
    "        \"chat_history\": x.get(\"chat_history\", []),\n",
    "        \"context\": format_docs(docs),\n",
    "        \"docs\": docs,\n",
    "    }\n",
    "\n",
    "done(\"Retrieve and prepare function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0db7f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Answer chain created\n"
     ]
    }
   ],
   "source": [
    "# Create answer-only chain (without sources)\n",
    "answer_chain = conversational_prompt | llm | StrOutputParser()\n",
    "\n",
    "done(\"Answer chain created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778760f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ RAG chain with sources created\n"
     ]
    }
   ],
   "source": [
    "# Combine using RunnableParallel to return both answer and sources\n",
    "conversational_rag_chain_with_sources = retrieve_and_prepare | RunnableParallel(\n",
    "    {\"answer\": answer_chain, \"source_documents\": lambda x: x[\"docs\"]}\n",
    ")\n",
    "\n",
    "done(\"RAG chain with sources created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd290f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap with message history\n",
    "conversational_chain_with_history_and_sources = RunnableWithMessageHistory(\n",
    "    runnable=conversational_rag_chain_with_sources,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task(\"Testing RAG chain with sources...\")\n",
    "\n",
    "session_id = \"test_with_sources\"\n",
    "\n",
    "result = conversational_chain_with_history_and_sources.invoke(\n",
    "    {\"question\": \"What is the Space Needle?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\" * 70)\n",
    "print(result[\"answer\"])\n",
    "print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SOURCE DOCUMENTS:\")\n",
    "print(\"=\" * 70)\n",
    "for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "    print(f\"\\n--- Source {i} ---\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "    if doc.metadata:\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "\n",
    "success(\"Chain successfully returns both answer and sources!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fe7f8",
   "metadata": {},
   "source": [
    "### üîó Step 06 ‚Äî Format Citations\n",
    "\n",
    "Create citation formatter for clear source display.\n",
    "\n",
    "**Goal:**\n",
    "- Format source documents into readable citations\n",
    "- Make it easy for users to verify information sources\n",
    "- Display metadata like location, coordinates, etc.\n",
    "\n",
    "**What we'll do:**\n",
    "1. Get sample documents using retriever (temporary, until API quota is restored)\n",
    "2. Understand the structure of Document objects\n",
    "3. Create a detailed citation formatter function\n",
    "4. Test the formatter\n",
    "\n",
    "**Note:** Once API quota is restored, we'll use `result[\"source_documents\"]` instead of calling retriever directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a41c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Retrieved 5 sample documents\n",
      "üìù Question: What is the Space Needle?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_question = \"What is the Space Needle?\"\n",
    "sample_docs = retriever.invoke(sample_question)\n",
    "\n",
    "data(f\"Retrieved {len(sample_docs)} sample documents\")\n",
    "print(f\"üìù Question: {sample_question}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ef0bff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Structure of a Document object:\n",
      "Type: <class 'langchain_core.documents.base.Document'>\n",
      "\n",
      "Attributes:\n",
      "- page_content: <class 'str'> (the actual text)\n",
      "- metadata: <class 'dict'> (additional information)\n",
      "\n",
      "Example:\n",
      "page_content:\n",
      "Name: Space Needle\n",
      "Location: Space Needle, 400 Broad Street, Seattle, WA 98109, United States of America\n",
      "Coordinates: 47.62051310002636, -122.34930359883188\n",
      "Description: The Space Needle is an observation tower in Seattle, Washington, United States. Considered to be an icon of the city, it has been designated a Seattle landmark. Located in the Lower Queen Anne neighborhood, it was built in the Seattle Center for the 1962 World's Fair, which drew more than 2.3 million visitors.\n",
      "At 605 ft (184 m) high, the Space Needle was once the tallest structure west of the Mississippi River in the United States. The tower is 138 ft (42 m) wide, weighs 9,550 short tons (8,660 metric tons), and is built to withstand winds of up to 200 mph (320 km/h) and earthquakes of up to 9.0 magnitude, as strong as the 1700 Cascadia earthquake.\n",
      "Elevators take visitors to an observation deck 520 ft (160 m) above ground in 41 seconds, which offers panoramic views of the downtown Seattle skyline, the Olympic and Cascade Mountains, Mount Rainier, Mount Baker, Elliott Bay, and various islands in Puget Sound. On April 19, 1999, the city's Landmarks Preservation Board designated the tower a historic landmark.\n",
      "...\n",
      "metadata: {'state': 'Washington', 'name': 'Space Needle', 'has_description': True, 'lon': -122.34930359883188, 'categories': 'access, access.yes, building, building.tourism, fee, internet_access, man_made, man_made.tower, tourism, tourism.attraction, tourism.sights, tourism.sights.tower, wheelchair, wheelchair.yes', 'city': 'Seattle', 'place_id': '51ea567bfd5a965ec05928ad27f96ccf4740f00102f901dce2c4000000000092030c5370616365204e6565646c65', 'country': 'United States of America', 'lat': 47.62051310002636}\n"
     ]
    }
   ],
   "source": [
    "# Show structure of a document\n",
    "\n",
    "print(\"üìÑ Structure of a Document object:\")\n",
    "if sample_docs:\n",
    "    doc = sample_docs[0]\n",
    "    print(f\"Type: {type(doc)}\")\n",
    "\n",
    "    print(\"\\nAttributes:\")\n",
    "    print(f\"- page_content: {type(doc.page_content)} (the actual text)\")\n",
    "    print(f\"- metadata: {type(doc.metadata)} (additional information)\")\n",
    "\n",
    "    print(\"\\nExample:\")\n",
    "    print(f\"page_content:\\n{doc.page_content}...\")\n",
    "    print(f\"metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ee76c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_citation(source_data):\n",
    "\n",
    "    citation = []\n",
    "\n",
    "    for i, doc in enumerate(source_data, 1):\n",
    "        # Build header\n",
    "        name = doc.metadata.get(\"name\", \"Unknown\")\n",
    "        citation_parts = [\n",
    "            f\"\\n{'='*70}\",\n",
    "            f\"üìå Source {i}: {name}\",\n",
    "            f\"{'='*70}\",\n",
    "        ]\n",
    "\n",
    "        # location info\n",
    "        city = doc.metadata.get(\"city\", \"Unknown\")\n",
    "        state = doc.metadata.get(\"state\", \"Unknown\")\n",
    "        country = doc.metadata.get(\"country\", \"Unknown\")\n",
    "        citation_parts.append(f\"\\nüìç Location: {city}, {state}, {country}\")\n",
    "\n",
    "        # coordinate info\n",
    "        lat = doc.metadata.get(\"lat\")\n",
    "        lon = doc.metadata.get(\"lon\")\n",
    "        if lat and lon:\n",
    "            citation_parts.append(f\"üìê Coordinates: ({lat}, {lon})\")\n",
    "\n",
    "        citation_parts.append(f\"\\nüìÑ Content:\\n{doc.page_content}\")\n",
    "\n",
    "        citation.append(\"\\n\".join(citation_parts))\n",
    "\n",
    "    return \"\\n\".join(citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "620f1bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Testing detailed citation formatter...\n",
      "\n",
      "======================================================================\n",
      "üìå Source 1: Space Needle\n",
      "======================================================================\n",
      "\n",
      "üìç Location: Seattle, Washington, United States of America\n",
      "üìê Coordinates: (47.62051310002636, -122.34930359883188)\n",
      "\n",
      "üìÑ Content:\n",
      "Name: Space Needle\n",
      "Location: Space Needle, 400 Broad Street, Seattle, WA 98109, United States of America\n",
      "Coordinates: 47.62051310002636, -122.34930359883188\n",
      "Description: The Space Needle is an observation tower in Seattle, Washington, United States. Considered to be an icon of the city, it has been designated a Seattle landmark. Located in the Lower Queen Anne neighborhood, it was built in the Seattle Center for the 1962 World's Fair, which drew more than 2.3 million visitors.\n",
      "At 605 ft (184 m) high, the Space Needle was once the tallest structure west of the Mississippi River in the United States. The tower is 138 ft (42 m) wide, weighs 9,550 short tons (8,660 metric tons), and is built to withstand winds of up to 200 mph (320 km/h) and earthquakes of up to 9.0 magnitude, as strong as the 1700 Cascadia earthquake.\n",
      "Elevators take visitors to an observation deck 520 ft (160 m) above ground in 41 seconds, which offers panoramic views of the downtown Seattle skyline, the Olympic and Cascade Mountains, Mount Rainier, Mount Baker, Elliott Bay, and various islands in Puget Sound. On April 19, 1999, the city's Landmarks Preservation Board designated the tower a historic landmark.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìå Source 2: Made in USA\n",
      "======================================================================\n",
      "\n",
      "üìç Location: Seattle, Washington, United States of America\n",
      "üìê Coordinates: (47.58013800003554, -122.32730359999996)\n",
      "\n",
      "üìÑ Content:\n",
      "Name: Made in USA\n",
      "Location: Made in USA, SODO Trail, Seattle, WA 98134, United States of America\n",
      "Coordinates: 47.58013800003554, -122.32730359999995\n",
      "Description: Made in USA is a 2005 sculpture by American artist Michael Davis, installed at the SODO light rail station in Seattle, in the U.S. state of Washington. It consists of a 24-foot-high (7.3 m) by 14-foot-wide (4.3 m) steel archway as well as a plaza with seating areas. The archway is composed of oversized tools, including a try square, spirit level, and carpenter pencil. The seating area includes benches shaped into I-beams and a cog, with cast bronze replicas of workbench tools soldered onto the granite tops. Both elements honor the industrial legacy of Seattle's SoDo neighborhood by using \"tools of the trade\".\n",
      "The archway element of the piece was installed in August 2005 as the first piece of public art on the Central Link line.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìå Source 3: 9 Spaces 9 Trees\n",
      "======================================================================\n",
      "\n",
      "üìç Location: Seattle, Washington, United States of America\n",
      "üìê Coordinates: (47.65644910001812, -122.311095)\n",
      "\n",
      "üìÑ Content:\n",
      "Name: 9 Spaces 9 Trees\n",
      "Location: 9 Spaces 9 Trees, George Washington Lane Northeast, Seattle, WA 98195, United States of America\n",
      "Coordinates: 47.65644910001812, -122.31109500000001\n",
      "Description: Nine Spaces Nine Trees (occasionally referred to as Nine Spaces, Nine Trees or 9 Spaces 9 Trees) is a 1982‚Äì1983 art installation by American artist Robert Irwin, located on the University of Washington campus in Seattle, Washington, in the United States. Upon its initial creation, Nine Spaces Nine Trees has a history of occupancy in the Seattle area. It was recreated in 2007. Irwin intended the work to stand for both public and private places and how they coincide.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìå Source 4: Virginia V\n",
      "======================================================================\n",
      "\n",
      "üìç Location: Seattle, Washington, United States of America\n",
      "üìê Coordinates: (47.62819735002461, -122.33702086608044)\n",
      "\n",
      "üìÑ Content:\n",
      "Name: Virginia V\n",
      "Location: Virginia V, Terry Avenue North, Seattle, WA 98109, United States of America\n",
      "Coordinates: 47.62819735002461, -122.33702086608044\n",
      "Description: The steamship Virginia V is the last operational example of a Puget Sound Mosquito Fleet steamer.  She was once part of a large fleet of small passenger and freight carrying ships that linked the islands and ports of Puget Sound in Washington state in the late 19th and early 20th centuries.  She is a Seattle landmark and a National Historic Landmark.\n",
      "Her original route was between the cities of Tacoma and Seattle, along the West Pass (also known as Colvos Passage) between Vashon Island and the Kitsap Peninsula.\n",
      "Today the ship operates from Heritage Wharf at Lake Union Park in Seattle.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìå Source 5: Seattle Center\n",
      "======================================================================\n",
      "\n",
      "üìç Location: Seattle, Washington, United States of America\n",
      "üìê Coordinates: (47.62156465002613, -122.35154202042388)\n",
      "\n",
      "üìÑ Content:\n",
      "Name: Seattle Center\n",
      "Location: Seattle Center, Belltown, Seattle, Washington, United States of America\n",
      "Coordinates: 47.62156465002613, -122.35154202042389\n",
      "Description: The Seattle Center is an entertainment, education, tourism and performing arts center located in the Lower Queen Anne neighborhood of Seattle, Washington, United States. Constructed for the 1962 World's Fair, the Seattle Center's landmark feature is the 605 ft (184 m) Space Needle, an official city landmark and globally recognized symbol of Seattle's skyline. Other notable attractions include Pacific Science Center, Climate Pledge Arena, and the Museum of Pop Culture (MoPOP), as well as McCaw Hall, which hosts both Seattle Opera and Pacific Northwest Ballet. The Seattle Center Monorail provides regular public transit service between the Seattle Center and Westlake Center in downtown Seattle, and is itself considered a tourist attraction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task(\"Testing detailed citation formatter...\")\n",
    "\n",
    "citation = format_citation(sample_docs)\n",
    "\n",
    "print(citation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c7d91",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 07 ‚Äî Test Complete System\n",
    "\n",
    "Test the enhanced RAG system with all features combined:\n",
    "- üß† Conversation memory (remembers context)\n",
    "- üìÑ Source documents (shows where answers come from)\n",
    "- üîó Formatted citations (easy to read)\n",
    "\n",
    "**Test scenario:** 3-turn conversation\n",
    "1. Initial question about a tourist attraction\n",
    "2. Follow-up using pronoun (tests memory)\n",
    "3. Context-dependent question (tests understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c08231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Complete System Test: 3-turn conversation\n",
    "# ============================================================\n",
    "\n",
    "task(\"Testing complete RAG system with memory and citations...\")\n",
    "\n",
    "# Create a session\n",
    "session_id = \"complete_system_demo\"\n",
    "\n",
    "# ============================================================\n",
    "# Turn 1: Initial question\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"üîµ\" * 35)\n",
    "print(\"TURN 1: Initial Question\")\n",
    "print(\"üîµ\" * 35)\n",
    "\n",
    "question1 = \"What is the Space Needle?\"\n",
    "print(f\"\\nüë§ User: {question1}\")\n",
    "\n",
    "result1 = conversational_chain_with_history_and_sources.invoke(\n",
    "    {\"question\": question1}, config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "print(f\"\\nü§ñ Assistant:\\n{result1['answer']}\")\n",
    "print(f\"\\n{format_citation(result1['source_documents'][:2])}\")\n",
    "\n",
    "# ============================================================\n",
    "# Turn 2: Follow-up with pronoun (tests memory)\n",
    "# ============================================================\n",
    "print(\"\\n\\n\" + \"üü¢\" * 35)\n",
    "print(\"TURN 2: Follow-up Question (Testing Memory)\")\n",
    "print(\"üü¢\" * 35)\n",
    "\n",
    "question2 = \"How tall is it?\"\n",
    "print(f\"\\nüë§ User: {question2}\")\n",
    "\n",
    "print(\"üí° Note: 'it' refers to Space Needle from previous question\")\n",
    "result2 = conversational_chain_with_history_and_sources.invoke(\n",
    "    {\"question\": question2}, config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "print(f\"\\nü§ñ Assistant:\\n{result2['answer']}\")\n",
    "print(f\"\\n{format_citation(result2['source_documents'][:2])}\")\n",
    "\n",
    "# ============================================================\n",
    "# Turn 3: Context-dependent question\n",
    "# ============================================================\n",
    "print(\"\\n\\n\" + \"üü°\" * 35)\n",
    "print(\"TURN 3: Context-dependent Question\")\n",
    "print(\"üü°\" * 35)\n",
    "\n",
    "question3 = \"What else is nearby?\"\n",
    "print(f\"\\nüë§ User: {question3}\")\n",
    "print(\"üí° Note: System should understand we're asking about Space Needle area\")\n",
    "\n",
    "result3 = conversational_chain_with_history_and_sources.invoke(\n",
    "    {\"question\": question3}, config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "print(f\"\\nü§ñ format_citation:\\n{result3['answer']}\")\n",
    "print(f\"\\n{format_citation(result3['source_documents'][:2])}\")\n",
    "success(\"Complete system test finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c4629",
   "metadata": {},
   "source": [
    "#### üéØ What We Verified\n",
    "\n",
    "‚úÖ **Conversation Memory Works**\n",
    "- Turn 2: System understood \"it\" refers to \"Space Needle\"\n",
    "- Turn 3: System understood \"nearby\" means near Space Needle\n",
    "- All context maintained across conversation\n",
    "\n",
    "‚úÖ **Source Documents Provided**\n",
    "- Every answer includes verifiable sources\n",
    "- Sources show exact content from Vector DB\n",
    "- Metadata includes location and coordinates\n",
    "\n",
    "‚úÖ **Citations Formatted Clearly**\n",
    "- Easy to read and verify\n",
    "- Includes all relevant information\n",
    "- Professional presentation\n",
    "\n",
    "#### üìä System Performance\n",
    "- **Total API calls:** 3 (one per question)\n",
    "- **Total messages stored:** 6 (3 user + 3 assistant)\n",
    "- **Sources per answer:** 2-5 documents\n",
    "- **Memory:** Persistent across entire session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1b4e6",
   "metadata": {},
   "source": [
    "## üìã Step 08 ‚Äî Chapter Summary\n",
    "\n",
    "Review what we've accomplished in this chapter and understand the complete architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b4ad73",
   "metadata": {},
   "source": [
    "### üéØ What We Accomplished\n",
    "\n",
    "In this chapter, we enhanced our basic RAG system with two critical features:\n",
    "\n",
    "#### 1Ô∏è‚É£ **Conversation Memory** (Steps 01-04)\n",
    "- ‚úÖ Added `ChatMessageHistory` to store conversation context\n",
    "- ‚úÖ Implemented `RunnableWithMessageHistory` to manage sessions\n",
    "- ‚úÖ Created conversational prompts with `MessagesPlaceholder`\n",
    "- ‚úÖ Enabled multi-turn dialogues with context awareness\n",
    "\n",
    "**Key Benefit:** The system can now understand follow-up questions and pronouns like \"it\", \"there\", \"that\", etc.\n",
    "\n",
    "#### 2Ô∏è‚É£ **Source Citations** (Steps 05-07)\n",
    "- ‚úÖ Modified RAG chain to return source documents\n",
    "- ‚úÖ Used `RunnableParallel` to output both answers and sources\n",
    "- ‚úÖ Created citation formatters for clear source display\n",
    "- ‚úÖ Tested the complete system with memory + citations\n",
    "\n",
    "**Key Benefit:** Users can verify where answers come from, increasing trust and transparency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel-rag-k8jaxz6c-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
